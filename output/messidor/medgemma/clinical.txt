Classification Report:
              precision    recall  f1-score   support

           0      0.694     0.714     0.704        35
           1      0.486     0.514     0.500        35
           2      0.541     0.571     0.556        35
           3      0.490     0.714     0.581        35
           4      0.643     0.257     0.367        35

    accuracy                          0.554       175
   macro avg      0.571     0.554     0.542       175
weighted avg      0.571     0.554     0.542       175

Confusion Matrix:
[[25 10  0  0  0]
 [10 18  7  0  0]
 [ 1  8 20  6  0]
 [ 0  0  5 25  5]
 [ 0  1  5 20  9]]
Binary Referral Classification Report (based on grade):
              precision    recall  f1-score   support

 No Referral       0.90      0.94      0.92       105
    Referral       0.91      0.84      0.87        70

    accuracy                           0.90       175
   macro avg       0.90      0.89      0.90       175
weighted avg       0.90      0.90      0.90       175

Confusion Matrix:
[[99  6]
 [11 59]]
Binary Referral Classification Report (based on `referral` field):
              precision    recall  f1-score   support

 No Referral       0.99      0.74      0.85       105
    Referral       0.72      0.99      0.83        70

    accuracy                           0.84       175
   macro avg       0.85      0.86      0.84       175
weighted avg       0.88      0.84      0.84       175

Confusion Matrix:
[[78 27]
 [ 1 69]]



 Where clinical context helps:
Multiclass grading (especially Grade 3):
Big F1 jump from 0.36 → 0.58 for Grade 3
→ Context may help clarify borderline cases between moderate and severe NPDR

Earlier grades (0–2):
Slightly fewer misclassifications overall

❌ Where it doesn’t help much:
Binary referral accuracy is virtually the same (90–91%)

Referral recall actually drops slightly (from 0.87 to 0.84)

Grade 4 gets confused more often with Grade 3 when context is added

